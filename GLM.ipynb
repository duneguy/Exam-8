{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Components of GLM\n",
    "<br><br>\n",
    "- <b>Systematic component:</b> The portion of the outcome that is explained by predictors in the model.\n",
    "<br><br>\n",
    "- <b>Random component:</b> The portion of the outcome driven by causes that are not accounted for in the model. Includes \"pure randomness\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Random Component\n",
    "<br>\n",
    "- Biggest assumption made about each risk ($y_i$) is it belongs to some exponential family of distributions:\n",
    "<br><br>\n",
    "$$y_i \\sim Exponential(\\mu_i, \\phi)$$\n",
    "\n",
    "- $\\mu_i$ is the mean of the record's distribution.<br>\n",
    "- $\\phi$ is the dispersion parameter. It is same for all records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$ Var(y_i) = \\frac{\\phi V(\\mu_i)}{\\omega_i}$$\n",
    "<br><br>\n",
    "- $V(u_i)$ is the variance function for the selected distribution.\n",
    "<br><br>\n",
    "- The mean of every exponential family distribution is $\\mu$.\n",
    "<br><br>\n",
    "- $w_i$ is the weight assigned to observation i. Twice the weight $\\rightarrow$ half the variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{array}{c|c}\n",
    "\\text{Distribution} & \\text{Variance Function [V($\\mu$)]}\\\\\n",
    "\\hline\n",
    "\\text{Normal} & 1 \\\\\n",
    "\\text{Poisson} & \\mu \\\\ \n",
    "\\text{Gamma} & \\mu^2 \\\\\n",
    "\\text{Inverse Gaussian} & \\mu^3 \\\\\n",
    "\\text{Negative Binomial} & \\mu(1+ \\kappa \\mu) \\\\\n",
    "\\text{Binomial} & \\mu(1-\\mu) \\\\\n",
    "\\text{Tweedie} & \\mu^p\n",
    "\\end{array}\n",
    "$$\n",
    "<br><br>\n",
    "- Variance is an increasing function of $\\mu$, which makes sense since higher expected losses have higher variance in losses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Systematic Component\n",
    "<br>\n",
    "$$g(\\mu_i) = \\beta_0+\\beta_1 x_{i1}+\\beta_2 x_{i2}+ \\cdots + \\beta_p x_{ip} + \\text{offset}$$\n",
    "\n",
    "- g(.) is the link function.\n",
    "    - Provides flexibility in relating the model prediction ($\\mu_i$) to predictors.\n",
    "    - Log link function allows for multiplicative rating structure.\n",
    "    - For binary target variables, we use logit link function. \n",
    "- RHS of the equation is called the <b>linear predictor</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Log Link\n",
    "<br>\n",
    "$$ln(\\mu_i) = \\beta_0+\\beta_1 x_{i1}+\\beta_2 x_{i2}+ \\cdots + \\beta_p x_{ip} + \\text{offset}$$\n",
    "<br>\n",
    "$$\\Downarrow$$\n",
    "<br>\n",
    "$$\\mu_i = e^{\\beta_0+\\beta_1 x_{i1}+\\beta_2 x_{i2}+ \\cdots + \\beta_p x_{ip} + \\text{offset}}$$\n",
    "<br>\n",
    "$$\\Downarrow$$\n",
    "<br>\n",
    "$$\\mu_i = e^{\\beta_0} \\cdot e^{\\beta_1 x_{i1}} \\cdot e^{\\beta_2 x_{i2}} \\cdot \\ldots  \\cdot e^{\\beta_p x_{ip}} \\cdot e^{\\text{offset}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Logit Link\n",
    "<br>\n",
    "$$ln \\left( \\frac{\\mu_i}{1-\\mu_i} \\right)= ln \\left( \\frac{\\text{Prob of event i occuring}}{\\text{Prob of event i not occuring}} \\right)= \\beta_0+\\beta_1 x_{i1}+\\beta_2 x_{i2}+ \\cdots + \\beta_p x_{ip} + \\text{offset}$$\n",
    "<br>\n",
    "$$\\Downarrow$$\n",
    "<br>\n",
    "$$\\frac{\\mu_i}{1-\\mu_i} = \\underbrace{e^{\\beta_0} \\cdot e^{\\beta_1 x_{i1}} \\cdot e^{\\beta_2 x_{i2}} \\cdot \\ldots  \\cdot e^{\\beta_p x_{ip}} \\cdot e^{\\text{offset}}}_{x_i}$$\n",
    "<br>\n",
    "$$\\Downarrow$$\n",
    "<br>\n",
    "$$\\mu_i = \\frac{1}{1+e^{-x_i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variable Significance\n",
    "\n",
    "- We need to test coefficient to determine if they are indeed significant / non-zero.\n",
    "- Helpful Statistics provided by GLM software:\n",
    "    - Standard Error\n",
    "    - P-Value\n",
    "    - Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Standard Error\n",
    "\n",
    "- Small std error gives us confidence that the estimated coefficient is close to the true value.\n",
    "- Larger datasets produce smaller std errors.\n",
    "- The larger the estimate of $\\phi$, the larger the std errors.\n",
    "    - Since variance depends on $\\phi$.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### P-Value\n",
    "\n",
    "- Derived from std error.\n",
    "- Gives the prob of observing the coefficient value or higher by chance if the true value is zero (or any chosen value).\n",
    "- P-value of .05 or less is desired when making variable selection decisions.\n",
    "    - If p-value is less than .05, we can reject the null  hypothesis that the true value of the variable is zero.\n",
    "- In GLM, this is based on relationship to the base class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Confidence Interval\n",
    "\n",
    "- Gives us the reasonable range of coefficient estimates.\n",
    "- Can be seen as complement of p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Continuous Variables\n",
    "\n",
    "- Predictor values are related to one another.\n",
    "- When log link is used, it is almost always appropriate to take the natural log of a continuous predictor.\n",
    "    - This allows the scale of the predictor to match the scale of the target variable.\n",
    "    - The response curve doesn't need to be restricted to the exponential form.\n",
    "        - Can have increasing at decreasing rate (generally seen in insurance models) and not just increasing at increasing rate.\n",
    "        - Can have linear relation.<br><br>\n",
    "\n",
    "$$ln(\\mu_i) = \\beta_0 + \\beta_{1} \\cdot ln(x_i)$$\n",
    "\n",
    "$$\\big\\Downarrow$$\n",
    "\n",
    "$$\\mu_i = e^{\\beta_0} \\cdot x_i^{\\beta_{1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Continuous_Vars.JPG'></center>\n",
    "\n",
    "- For negative beta estimates (logged case), the graph is flipped around y = 0 axis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "- Assume base AOI is 100k\n",
    "- Record's AOI is 200K\n",
    "- The coefficient estimate is .62\n",
    "- Then indicated relativity for 200k AOI:\n",
    "\n",
    "$$\\text{Relativity =} \\frac{\\text{200,000}^{.62}}{\\text{100,000}^{.62}} = 2^{.62}= 1.54$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Cases where it may be desirable to include continuous variable in unlogged form\n",
    "\n",
    "- When x is a temporal variable meant to pickup trend.\n",
    "- Driver age variable has higher pp value for younger drivers and senior drivers.\n",
    "    - Relationship is no longer linear with the logged mean.\n",
    "- Unlogged form should rarely be used for continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table><tr><td><img src='images/GLM_Eval_1.JPG'></td><td><img src='images/GLM_Eval_2.JPG'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The low p-value for van means that we are not confident that this class is different from the base class \"sedan\".\n",
    "- The error bar for \"van\" crosses the y = 0 line, indicating that the parameter estimate is not significant at the 95% confidence level.\n",
    "- When we set \"van\" as the base class, all the error bars increase in size and raises p-values.\n",
    "    - The predicted coefficients are still equivalent.\n",
    "        - Can subtract coefficient of \"sedan\" to get the same coefficients as above.<br><br>\n",
    "        \n",
    "<center><img src='images/GLM_Eval_3.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Use Base Class with the most data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Offsets\n",
    "\n",
    "- Used when we are leaving some of the variables untouched (i.e., territory relativities, deductible factors are usually based on loss elimination-based techniques, etc.)\n",
    "- The coefficient is constrained to be 1.\n",
    "- When using log link, the offset variable is also logged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Severity Model Distributions\n",
    "\n",
    "- <b>Gamma</b>\n",
    "    - Most commonly used.\n",
    "- <b>Inverse Gaussian</b>\n",
    "    - Wider tail and sharper peak than Gamma.\n",
    "- Both are right-skewed and have lower bound at 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Frequency Model Distributions\n",
    "\n",
    "- <b>Poisson</b>\n",
    "    - Most commonly used.\n",
    "    - Models the count of events occuring within a fixed timeframe.\n",
    "    - GLM implementation allows it to be continuous as well.\n",
    "    - ODP is used because in addition to the Poisson variance, there is variance in the Poisson mean ($\\mu$).\n",
    "    - Poisson and ODP distributions produce the same estimates of coefficients.\n",
    "        - Model diagnostics might be too optimistic under Poisson.\n",
    "            - Due to lower variance since $\\phi$ = 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- <b>Negative Binomial: </b>\n",
    "    \n",
    "$$y \\sim Poisson(\\mu = \\theta), \\\\ \\theta \\sim Gamma(....)$$<br>\n",
    "\n",
    "- $\\phi$ = 1\n",
    "- $\\kappa$ is the overdispersion parameter."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
