{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Measures of Model Fit\n",
    "- Log-Likelihood\n",
    "- Deviance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Log-Likelihood\n",
    "\n",
    "- GLM produces mean and dispersion values. These together with the selected distribution give you the probability of observing the outcome.\n",
    "    - Multiply prob(outcomes) for each record $\\rightarrow$ likelihood.\n",
    "        - GLM is fit by finding parameters that maximize the likelihood.\n",
    "        - Log(likelihood) since these numbers are extremely small.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Log-likelihood scale:\n",
    "    - <b>Null Model:</b>  No predictors. Only intercept term.\n",
    "    - <b>Saturated Model:</b> One predictor for each record.<br><br>\n",
    "\n",
    "$$\\require{AMScd}\n",
    "\\begin{CD}\n",
    "    \\text{Null Model} @<worse<< \\text{Model} @>better>> \\text{Saturated Model}\n",
    "\\end{CD}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deviance\n",
    "<br><br>\n",
    "$$ \\text{Scaled Deviance = } 2 \\cdot (ll_{saturated} - ll_{model})$$\n",
    "<br>\n",
    "- Can be thought of as the magnitude by which the model is far from \"perfect\" model.\n",
    "- Fitted GLM coefficients minimize deviance.\n",
    "- Adding predictors always reduces deviance since more degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Limitations on the Use of Log-Likelihood and Deviance\n",
    "\n",
    "1. Model comparison only valid for identical datasets.\n",
    "    - If different datasets used then sum of log-likelihood would be necessarily different.\n",
    "    - When adding variables, some rows could be dropped which invalidates this comparison.<br><br>\n",
    "2. The assumed distribution and the dispersion parameter must be identical.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Comparing Models\n",
    "\n",
    "- Nested models\n",
    "    - F-Test<br><br>\n",
    "- Non-nested models \n",
    "    - AIC\n",
    "    - BIC\n",
    "    - Deviance Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## F-Test\n",
    "\n",
    "- Only valid if a model is subset of another model (i.e. model after adding/removing variable(s)).\n",
    "- <b>Question answered by F-Test:</b> Did the added predictors significantly reduce the deviance?<br><br>\n",
    "\n",
    "$$F = \\frac{\\text{UD}_{Small}-\\text{UD}_{Big}}{(\\text{# of added params}) \\cdot \\hat{\\phi}_{Big}}$$<br><br>\n",
    "$$Dof = \\frac{\\text{# of added params}}{\\text{# of records - # of params$_{Big}$}}$$<br><br>\n",
    "\n",
    "$\\hat{\\phi}_B$ is a good esimate for the amount by which we can expect deviance to reduce for each new added parameter to the model with no predictive power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src = 'images/Deviance_F.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## AIC and BIC\n",
    "\n",
    "$$ \\begin{align}\n",
    "AIC & = -2 \\cdot \\text{log-likelihood} + 2p \\\\ \\\\\n",
    "BIC & = -2 \\cdot \\text{log-likelihood} + p \\cdot log(n)\n",
    "\\end{align}$$<br><br>\n",
    "\n",
    "- Smaller values are desired - means lower penalty term.\n",
    "- Authors prefer AIC since BIC tends to overpenalize due to inclusion of log(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Deviance Residuals\n",
    "<br><br>\n",
    "$$\\begin{align}\n",
    "\\text{Deviance Residual} & = \\sqrt{2\\phi \\cdot \\big(ln f(y_i|\\mu_i = y_i) - ln f(y_i|\\mu_i = \\mu_i)\\big)} \\cdot sign(y_i-\\mu_i) \\\\ \\\\\n",
    "& = \\text{(Record's contribution to the deviance)}  \\cdot sign(y_i-\\mu_i)\n",
    "\\end{align}$$<br><br>\n",
    "\n",
    "- Can be thought of as raw residual adjusted for the shape of the assumed GLM distribution $\\rightarrow$ it should be normally distributed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Properties of deviance residuals\n",
    "\n",
    "1. They follow no predictable pattern.\n",
    "2. They are normally distributed with constant variance.\n",
    "    - Constant variance/<b>homoscedasticity</b> - The deviance residuals don't spread as $\\mu$ increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Ways of assessing normality of deviance residuals\n",
    "\n",
    "- Create histrogram of deviance residuals and fit normal curve to it.\n",
    "- Create q-q plot. Points should fall on x = y line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Dev_Resid.JPG'></center><br><br>\n",
    "\n",
    "- The histogram seems to have more right-skew as compared to normal distribution.\n",
    "- Q-Q plot shows that sample has more values on the left and right than expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Discrete distributions and deviance residuals\n",
    "\n",
    "- Deviance residuals for discrete distributions do not follow a normal distribution.\n",
    "    - Deviance residuals do not adjust for discreteness.\n",
    "        - You end up with cluster of values.<br><br>\n",
    "        \n",
    "<b>Solution</b><br>\n",
    "- Use randomized quantile residuals - adds random jitter to the discrete points so that they are spread smoothly over the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Assessing Model Stability\n",
    "\n",
    "- Use <b>Cook's distance</b> to identify most influential records.   \n",
    "    - Give less weight to these records if their removal dramatically changes the parameter estimates.<br><br>\n",
    "- Use <b>cross validation</b> to see if the parameter estimates are consistent between different folds.<br><br>\n",
    "- Use <b>bootstrapping</b> to create new datasets and fit parameters.\n",
    "    - Provides a sense of stability of parameter estimates."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
