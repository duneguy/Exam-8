{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Excess loss factor (ELF) or Excess loss Pure Premium factor (ELPPF)  or Excess ratio<br><br> \n",
    "\n",
    "$$R(L) = \\frac{E[X] - E[X;L]}{E[X]}$$<br><br>\n",
    "\n",
    "- <b>Hazard Group:</b> Collection of workers compensation classifications that have relatively similar expected ELFs over a broad range of limits.\n",
    "    - Defined on a country-wide basis.<br><br>\n",
    "    \n",
    "- Assumes mix of injuries within a class does not vary by state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Goal and Products\n",
    "\n",
    "- <b>Goal:</b> Produce new hazard group mappings that exist at the countrywide level.<br><br>\n",
    "- Final product:<br><br>\n",
    "$$\n",
    "\\begin{array}{c|c}\n",
    "\\text{State} & \\text{Hazard Group} & \\text{Limt} & \\text{ELF}\\\\\n",
    "\\hline\n",
    "\\text{TX} &  \\text{A} & \\text{\\$100,000} & \\cdots \\\\\n",
    "\\text{TX} &  \\text{A} & \\text{\\$250,000} & \\cdots \\\\\n",
    "\\text{TX} &  \\text{A} & \\text{\\$500,000} & \\cdots \\\\\n",
    "\\text{TX} &  \\text{A} & \\text{\\$1,000,000} & \\cdots \\\\\n",
    "\\cdots & \\cdots & \\cdots & \\cdots\n",
    "\\end{array}$$\n",
    "\n",
    "\n",
    "- Each ELF is a weighted average of injury types for the state and HG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Methodology\n",
    "- Let i = injury type and j = hazard group.\n",
    "- S(.) is the excess ratio calculated using entry ratio CDF. (i.e. area above the selected entry ratio).<br><br>\n",
    "\n",
    "$$R_j(L) = \\sum_i w_{\\text{i,j}} \\cdot S_i\\left(\\frac{L}{\\mu_{\\text{i,j}}} = r_{i,j}\\right)$$<br>\n",
    "\n",
    "- Similarly, we calculate the class excess ratios by limit:<br><br>\n",
    "\n",
    "$$R_c(L) = \\sum_i w_{\\text{i,c}} \\cdot S_i\\left(\\frac{L}{\\mu_{\\text{i,c}}} = r_{i,c}\\right)$$<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Now, we have the following two vectors:<br><br>\n",
    "\n",
    "$$R_c = \\big(R_c(L_1),R_c(L_2),\\ldots,R_c(L_n)\\big)$$<br>\n",
    "$$R_{HG} = \\big(R_{HG}(L_1),R_{HG}(L_2),\\ldots,R_{HG}(L_n)\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Then:<br><br>\n",
    "\n",
    "$$R_c^{\\text{final}}(L_n) = z_c \\cdot R_c(L_n) + (1-z_c) R_{HG}(L_n)$$<br>\n",
    "\n",
    "- Assigned credibility does not differ by limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Let n = # of claims in the class and k = avg # of claims per class.\n",
    "- Credibility formula used in the paper:<br><br>\n",
    "$$z = min \\left(1.5 \\left(\\frac{n}{n+k}\\right),1 \\right)$$<br><br>\n",
    "\n",
    "#### An issue with the data\n",
    "- Claim count and premium data by class was highly skewed.\n",
    "    - Avg claim count per class was 10 times the median claim count per class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='images/Robert_1.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Robert_2.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Number of Hazard Groups\n",
    "\n",
    "- They used $R_c^{\\text{final}}(L_n)$ in the analysis.\n",
    "- Only used classes with 75%+ credibility for correlation calcs.\n",
    "    - Else, correlations would have been skewed towards the overall HGs.<br><br>\n",
    "- Decided not to use fewer than 5 limits because of the need to cover commonly used limits in retro rating.<br><br>\n",
    "- Did not use more than 5 limits due to:\n",
    "    - XS ratios at any pair of limits are highly correlation across classes.\n",
    "    - Limits below 100K were heavily represented in the 17 limits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Distance Metric\n",
    "\n",
    "- NCCI used the Euclidean distance ($L^2$):<br><br>\n",
    "\n",
    "$$||x-y||_2 = \\sqrt{\\sum_{i=1}^n (x_i-y_i)^2}$$\n",
    "\n",
    "#### Advantage\n",
    "- Penalizes large deviations - one large deviation is seen worse than many small deviations.\n",
    "\n",
    "#### Reason for using this metric\n",
    "- Analysis was not sensitive to the distance measure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $L_1$ metric (not used)\n",
    "\n",
    "- $L_1$ metric:<br><br>\n",
    "\n",
    "$$||x-y||_1 = \\sum_{i=1}^n |x_i-y_i|$$<br>\n",
    "\n",
    "#### Reason why one might use it\n",
    "- It minimizes the relativite error in estimating XS premium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- True expected XS loss for policy = P x PLR x R$_c$(L) $\\qquad [\\color{blue}{\\text{Think left to right}}]$<br><br>\n",
    "- Estimated expected XS loss for policy = P x PLR x R$_{\\text{HG}}$(L)<br><br>\n",
    "\n",
    "\n",
    "$$\\text{Relative error for using HG to est prem for limit L} = PLR \\cdot |R_{HG}(L)-R_c(L)|$$<br><br>\n",
    "\n",
    "- If each limit is equally likely to be chosen then:\n",
    "\n",
    "$$\\text{Expected relative error} = \\sum_{i=1}^n \\frac{PLR}{n} \\cdot |R_{HG}(L_i)-R_c(L_i)|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Standardization\n",
    "\n",
    "- <b>Purpose:</b> Done to reduce the impact of outliers on clustering algorithm.<br><br>\n",
    "- <b>Appropriate:</b> When spread of values is due to randomness.<br><br>\n",
    "- <b>Not appropriate:</b> When spread is due to the presence of subclasses.\n",
    "    - Basically, can't have cluster of entry ratios.<br>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Reasons for not using standardization\n",
    "\n",
    "1. The resulting HGs using standardization didn't differ much from not using it.<br><br>\n",
    "2. You lose the unit of measure $\\left(\\frac{\\text{Dollars of XS losses}}{\\text{Dollars of total losses}} \\right)$<br><br>\n",
    "3. All XS ratios are between 0 and 1. Standardization could have led to values outside this range.<br><br>\n",
    "4. Greater range of XS ratios at lower limits. Less weight would have been given to XS ratios at lower limits, which are supported by actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cluster Analysis\n",
    "\n",
    "- <b>Objective:</b> Group classes with similar vectors of excess ratios.<br><br>\n",
    "- <b>Non-hierrarchical cluster analysis:</b> Seeks to best partition to get n clusters.\n",
    "    - Used for the analysis.\n",
    "- <b>Hierrarchical cluster analysis:</b> k clusters is divided to get k+1 clusters.<br><br>\n",
    "\n",
    "- This procedure attempts to minimize the within variance and maximize the between variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### K-means clustering\n",
    "<br><br>\n",
    "<center><img src='images/Clustering.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- S = Total variance/covariance matrix\n",
    "- W* = Within variance/covariance matrix\n",
    "- B* = Between variance/covariance matrix<br><br>\n",
    "\n",
    "$$S = W^* + B^*$$<br><br>\n",
    "\n",
    "- Trace(S) = total variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='images/Robert_3.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Robert_4.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Robert_5.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optimal Number of HGs\n",
    "\n",
    "- Calinski and Harabasz statistic (aka Pseudo-F test) performed the best.\n",
    "    - Higher values better.\n",
    "- n = # of classes\n",
    "- k = # of HGs<br><br>\n",
    "\n",
    "$$\\text{C-H Statistic} = \\frac{\\frac{\\text{trace(B)}}{k-1}}{\\frac{\\text{trace(W)}}{n-k}} = \\frac{\\text{Corrected Between Variance}}{\\text{Corrected Within Variance}}$$<br><br>\n",
    "\n",
    "- Corrected for degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Cubic Clustering Criteria (CCC)\n",
    "\n",
    "- Compares variance explained by a given set of clusters to that expected when clusters are formed at random based on multi-dimensional uniform distribution.\n",
    "    - Higher values desired.\n",
    "    \n",
    "#### Reason not used\n",
    "- CCC is less reliable when data is highly correlated.\n",
    "- 9 HGs produced crossover.\n",
    "- C-H statistic outperformed CCC in a separate study (Milligan and Cooper).\n",
    "- Using high and fully credible classes, the optimal number was 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src='images/Robert_6.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Robert_7.JPG'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src='images/Robert_8.JPG'></center>\n",
    "<center><img src='images/Robert_9.JPG'></center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
